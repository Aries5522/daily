* 神经网络中权重共享的是？
  
  solu:卷积神经网络、循环神经网络
  首先要明白权重共享的意思,在卷积神经网络中,从输入层到第一个隐藏层,都是通过比如3*3大小的卷积核做卷积实现的,那么这个卷积核在这一层里面是不变的,里面的权重信息在这一层是共享的.

* 神经网络激活函数,了解sigmoid,relu,tanh以及变体.
  
 >此处知识点,对比下相关的激活函数.sigmoid,relu,tanh
 >--------------------------
 > * $$sigmiod(x)=1/( 1+e^   {-x})$$
 > sigmoid函数的导数最大值为0.25,因为求导书之后为$m/((1+m)^2)$m取值范围为0到1,此函数的极值为0.25,在m=1取到,但是sigmoid函数有三个缺点:
 > * 梯度容易消失
 > * 梯度只能正向或者反向更新,收敛速度慢
 > * 幂运算耗时
 > 
 > tanh函数(取值范围-1到1,解决了只能正向和反向传播问题,但是还是会梯度消失,并且幂运算慢
 > + $$ tanhx=(e^x-e^(-x))/((e^x+e^(-x)))$$
 > relu函数
 > + $$relu=max(0,x)$$
  > 解决梯度消失问题,收敛快,计算块,网络稀疏,缓解过拟合.
 > 容易出现问题,网络参数初始化不好的话,导致部分参数永远不会更新.

+ GRU和LSTM 了解一下
  
  首先需要了解rnn,Lstm和GRU是Rnn改进算法

+ Attention机制在NLP和CV中的运用.

+ bn层作用,以及bn层
  
+ SVM面试题总结
  
   +介绍svm:是一个定义在特征空间上的间隔最大的二分类线性模型 .


+ 深度学习相关
+ 激活方式总结
+ Loss总结
+ 优化器总结
+ 卷积方式总结
+ trick总结
  