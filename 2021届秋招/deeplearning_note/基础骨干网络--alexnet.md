alexnet
===============
去掉tanh（）函数改用relu做激活函数
数据增强的手段
dropout防止过拟合
多gpu计算