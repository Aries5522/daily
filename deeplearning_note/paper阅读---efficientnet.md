EfficientNet

传统意义上,在训练卷积神经网络的时候.
+ 网络深度(d):加深网络深度有利于提取更加丰富和复杂的特征信息,但是随着网络加深到一种地步,网络的深度对最终精度影响就不会那么大,比如resnet101和resnet1000层的效果可能差不太多.
+ 网络宽度(w):网络越宽,捕获细粒度特征.但是难获得高级别的特征
+ 分辨率(r):更高分辨率的图像能捕获更加具有细粒度的特征

但是这三者实验证明相互依赖,只提升一种到很高的地步,不会带来多高的精度增益,因此需要协调的去增加深度,宽度和图像分辨率,也就是说这三者之间有一个平衡的关系
再者网络卷积计算的flop数与d,和w^2以及r^2成正比,也就是深度增加一倍,flops增加一倍,w和r增加一倍,flops变为以前4倍,作者对宽度深度和分辨率做了一个约束.
在baseline(网格搜索得到)基础之上,逐渐计算出efficientnetB1-B7,在当前大多数数据级上表现极好,速度快,精度高